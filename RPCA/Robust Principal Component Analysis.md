# Robust Principal Component Analysis笔记

## Abstract

对于一个矩阵，把他分解成一个低秩矩阵和一个稀疏矩阵的合。在一定情况下，可以通过解一个凸优化问题PCA，就可以精确的分解出低秩和稀疏分量。另外，即使有一部分数据丢失损坏，也可以恢复出他的主成分。这个算法可以运用在人脸识别中消除阴影高光，也可以在视频监控领域中在复杂的背景里识别出对象。

## 1 Introduction

### 1.1 Motivation

对一个大矩阵$M$,我们可以把它分解成:
$$
M=L_0+S_0
$$

其中$L_0$是低秩的，$S_0$是稀疏的，这两个分量任意大小，维度。如果我们将数据点各自张成一个列向量，他们组成的矩阵M应当是低秩的，可以表示为:
$$
M=L_0+N_0
$$
其中L0是低秩的，N_0是一个小的扰动矩阵（噪声），传统PCA则为一个优化问题
$$
minimize~~~~~~~~~~~~ \|M-L\| \\
subject\ to\ ~~~~~~rank(L) \leq k
$$

> 本论文中，$\|M\|$是第二范数，就是$M$的最大的奇异值

这个优化问题可以用SVD解，并且当噪音$N_0$非常小以及高斯分布时，具有一些最优性质。

**RPCA** . PCA广泛应用于数据分析和降维，但是对于数据要求太高。对于严重破坏的数据会令估计值$\hat{L}$严重偏离真实值$L_0$。

**应用**：

1. 视频监控，给定视频监控序列，可以识别出来主要的目标活动。
2. 人脸识别，可以去除人脸中阴影，亮度等缺陷。
3. 潜在语义索引，可以检索出每个文档的几个关键词。
4. 排序协同预测，这是一个矩阵补全问题，顾客给定对于商品的排名，预测出给定用户任何产品的偏好。

以上应用基础均为本文的超高维矩阵在更广泛条件下的低秩稀疏矩阵分解。



### 1.2 A surprising message

本文中，$\|M\|_*=\sum_i{\sigma_i(M)}$表示矩阵M的核范数，即M的奇异值之和。

$\|M\|_1=\sum_{ij}{M_{ij}}$表示矩阵M的$l_1$范数(在$R^{n_1*n_2}$上的大向量)。



**PCP**：弱假设
$$
minimize ~~			\|L\|_* + \lambda \|S\|_1\\
subject\ to ~~~~~~~	L+S=M
$$
虽在此情况，$L_0$的秩在矩阵维度上升时呈线性增长，$S_0$误差为常数，但它依旧适用于多类型真实数据。



### 1.3 When does separation make sense?

为避免$L_0$与$S_0$混淆（即一个矩阵又稀疏又低秩），我们令低秩矩阵不稀疏。本文引入一个假设，关于低秩向量的奇异值向量。
$$
L_0=U\sum V^*=\sum^r_{i=1}\sigma_iu_iv_i^*
$$
注：

​	$r$：$M$的秩

​	$\sigma_1 ...\sigma_r$：正奇异值。

​	$U=[u_1 ,... ,u_r]$：左奇异向量

​	$V=[v_1 ,... ,v_r]$：右奇异向量

​	

在无序条件下参数$\mu$：
$$
\max_i \|U^*e_i\|^2 \leq \frac{\mu r}{n_1}~~~~,~~~~
\max_i \|V^*e_i\|^2 \leq \frac{\mu r}{n_2}\\
and ~~~\|UV^*\|_\infty \leq \sqrt{\frac{\mu r}{n_1n_2}}
$$
在此：$\|M\|_\infty = \max_{i,j}{|M_{ij}|}$ 	$M$的$l_0$范数

注意：在列空间$U(P_U=UU^*)$上的正交投影$P_U$，等于$\max_i{\|P_Ue_i\|^2} \leq \frac{\mu r}{n}$，$P_V$亦是如此。

对于$\mu$的较小值，奇异向量相当分散（不稀疏）。为了避免另一个稀疏矩阵秩低的问题，即稀疏矩阵的非零项出现在一列，我们假设稀疏矩阵的稀疏模式是均匀随机的。



### 1.4 Main result

PCP在矩阵不太大时，可以完美恢复低秩分量与稀疏分量。

在下文中，$n_{(1)}=\max(n_1,n_2)n_{(2)}=\min(n_1,n_2)$

假设$L_0$是$n \times  n$的，服从
$$
\max_i \|U^*e_i\|^2 \leq \frac{\mu r}{n_1}~~~~,~~~~\max_i \|V^*e_i\|^2 \leq \frac{\mu r}{n_2}\\and ~~~\|UV^*\|_\infty \leq \sqrt{\frac{\mu r}{n_1n_2}}
$$
$S_0$的支持集均匀分布在所有基数集合$m$中，有一个数值常量c，PCP的$\lambda =\frac{1}{\sqrt n}$的可能性至少为$1-cn^{-10}$(在支持$S_0$的选择上)，也就是$\hat{L}=L_0,\hat{S}=S_0$，如果
$$
rank(L_0) \leq \rho_rn\mu^{-1}(\log n)^{-2}~~~and~~~m \leq \rho_sn^2.
$$
其中$L_0$是$n_1 \times n_2$的矩阵，$\rho_r,\rho_s$是正数值常量。如果$rank(L_0) \leq \rho_rn_{(2)}\mu^{-1}(\log n_{(1)})^{-2}~and~m \leq \rho_sn_1n_2$，PCP的$\lambda =\frac{1}{\sqrt{n_{(1)}}}$概率至少为$1-cn_{(1)}^{-10}$。

换句话说，如果矩阵L0的奇异向量或主成分分布合理，那么它可以以接近1的概率从任意且完全未知的破坏模式中恢复(只要它们是随机分布的)。实际上，对于秩较大的值，也就是在$n=(\log n)^2$的阶上，当它不太大时，这个方法是有效的。我们想强调的是，在我们的假设中唯一的“随机性”涉及到$ S_0 $的非零项的位置;其他一切都是确定性的。特别地，关于$L_0$我们需要的是它的奇异向量不是spiky的。同样，我们对$S_0$的非零项的大小或符号不做任何假设。为了避免歧义，我们的$S_0$模型是这样的:取任意矩阵$S$并将其在随机集合$\Omega^c$上的项设为零。

一个值得注意的事实是，我们的算法中没有调优参数。在定理的假设下，最小化
$$
\|L\|_*+\frac1{\sqrt{n_{(1)}}}\|S\|_1,n_{(1)}=\max(n_1,n_2)
$$
总会返回正确答案。$\lambda$并不需要我们正确的估算值去平衡两个参数，无论$L_0,S_0$是什么，$\lambda =\frac{1}{\sqrt{n_{(1)}}}$都是一个正确的选择，数学分析可以证明，事实上定理的证明给出了 一系列正确的值，我们只是在此选了一个比较简单的值。

另外，如果以降低$\rho_r$的值为代价，$1-O(n^{-\beta})(or 1-O(n_{(1)}^{-\beta})) ,\beta >0$会以更大概率成功。



### 1.5 Connections with prior work and innovations

在过去的一两年里，我们看到了关于[8]中引入的矩阵补全问题的科学文献的快速发展，参见[7,10,22,23,29]和其中的参考文献。简而言之，矩阵补全问题就是从一个低秩矩阵的一小部分元素中恢复出一个低秩矩阵，并通过扩展，从少量的线性泛函中恢复出一个低秩矩阵。虽然已有[29]的其他方法被提出，但选择的方法是使用凸优化[7,10,22,23,45]:在所有与数据一致的矩阵中，仅使用最小核范数。以上引用的论文都证明了这种方法的数学有效性，我们的数学分析借鉴了这方面的文献，尤其是[8]的先驱。我们的方法也很大程度上依赖于David Gross在量子态体层摄影中引入的强大的思想和优雅的技术[22,23]。特别地，巧妙的golfing方案[22]在我们的分析中起着至关重要的作用，我们为这个方案引入了两种新的模式。

尽管有这些相似之处，我们的观点在几个方面与矩阵补全的文献不同。首先，我们的结果显然是不同的。第二，我们可以把我们的分离问题，以及低秩分量的恢复，看作一个矩阵补全问题。事实上，我们不是有一小部分观测条目可用而另一部分缺失，而是有一小部分可用，但我们不知道哪一个可用，而另一个不是缺失，而是完全崩溃了。尽管这是一个比较困难的问题，但我们的算法的一种思路是，它可以同时检测损坏的条目，并将低秩组件完美地匹配到其他被认为可靠的条目。从这个意义上说，我们的方法和结果超越了矩阵补全。第三，我们引入了一个新的反随机参数，它允许我们x稀疏分量的非零分量的符号。我们相信这项技术将有许多应用。其中一个应用是在压缩感知领域，对信号符号的随机性的假设是常见的，而且仅仅是出于方便而非必要;这一点很重要，因为假设独立的信号符号对许多实际应用来说没有多大意义，因为涉及的信号都是非负的(如图像)。

我们在前面提到了相关的工作[12]，它也考虑了将给定的数据矩阵分解成稀疏和低秩分量的问题，并为凸规划的成功提供了有效的条件。这些条件用两个量来表示。第一个是$l_\infty$范数和算子范数之间的最大比率，限制在行或列空间与$L_0$的行或列空间一致的矩阵所生成的子空间内。第二个是算子范数和$L_\infty$范数之间的最大比率，限制在矩阵的子空间中，这些矩阵在$S_0$的支持下消失。Chandrasekaran等研究表明，当这两个量的乘积很小时，在正则化参数[12]的某一区间内，恢复是精确的。